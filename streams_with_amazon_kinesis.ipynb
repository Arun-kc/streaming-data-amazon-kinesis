{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_name =  'kinesis-word-stream'\n",
    "region = 'us-east-2'\n",
    "aws_profile = 'streaming-data-amazon-kinesis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto\n",
    "from boto.kinesis.exceptions import ResourceInUseException\n",
    "import os\n",
    "import time\n",
    "\n",
    "if aws_profile:\n",
    "    os.environ['AWS_PROFILE'] = aws_profile\n",
    "\n",
    "# connect to the kinesis\n",
    "kinesis = boto.kinesis.connect_to_region(region)\n",
    "\n",
    "def get_status():\n",
    "    r = kinesis.describe_stream(stream_name)\n",
    "    description = r.get('StreamDescription')\n",
    "    status = description.get('StreamStatus')\n",
    "    return status\n",
    "\n",
    "def create_stream(stream_name):\n",
    "    try:\n",
    "        # create the stream\n",
    "        kinesis.create_stream(stream_name, 1)\n",
    "        print('stream {} created in region {}'.format(stream_name, region))\n",
    "    except ResourceInUseException:\n",
    "        print('stream {} already exists in region {}'.format(stream_name, region))\n",
    "\n",
    "\n",
    "    # wait for the stream to become active\n",
    "    while get_status() != 'ACTIVE':\n",
    "        time.sleep(1)\n",
    "    print('stream {} is active'.format(stream_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream kinesis-word-stream created in region us-east-2\n",
      "stream kinesis-word-stream is active\n"
     ]
    }
   ],
   "source": [
    "create_stream(stream_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a producer\n",
    "\n",
    "Produces a stream of data. \n",
    "\n",
    "partition_key = ip address\n",
    "data = UNIX timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "from boto.kinesis.exceptions import ResourceNotFoundException\n",
    "\n",
    "class KinesisProducer(threading.Thread):\n",
    "    \"\"\"Producer class for AWS Kinesis streams\n",
    "\n",
    "    This class will emit records with the IP addresses as partition key and\n",
    "    the emission timestamps as data\"\"\"\n",
    "\n",
    "    def __init__(self, stream_name, sleep_interval=None, ip_addr='8.8.8.8'):\n",
    "        self.stream_name = stream_name\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.ip_addr = ip_addr\n",
    "        super().__init__()\n",
    "\n",
    "    def put_record(self):\n",
    "        \"\"\"put a single record to the stream\"\"\"\n",
    "        timestamp = datetime.datetime.utcnow()\n",
    "        part_key = self.ip_addr\n",
    "        data = timestamp.isoformat()\n",
    "\n",
    "        kinesis.put_record(self.stream_name, data, part_key)\n",
    "\n",
    "    def run_continously(self):\n",
    "        \"\"\"put a record at regular intervals\"\"\"\n",
    "        while True:\n",
    "            self.put_record()\n",
    "            time.sleep(self.sleep_interval)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"run the producer\"\"\"\n",
    "        try:\n",
    "            if self.sleep_interval:\n",
    "                self.run_continously()\n",
    "            else:\n",
    "                self.put_record()\n",
    "        except ResourceNotFoundException:\n",
    "            print('stream {} not found. Exiting'.format(self.stream_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer1 = KinesisProducer(stream_name, sleep_interval=2, ip_addr='8.8.8.8')\n",
    "producer2 = KinesisProducer(stream_name, sleep_interval=5, ip_addr='8.8.8.9')\n",
    "producer1.start()\n",
    "producer2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a consumer\n",
    "\n",
    "Consumes the data flown from the producer. It just prints out the key and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto.kinesis.exceptions import ProvisionedThroughputExceededException\n",
    "import datetime\n",
    "\n",
    "class KinesisConsumer:\n",
    "    \"\"\"Generic Consumer for Amazon Kinesis Streams\"\"\"\n",
    "    def __init__(self, stream_name, shard_id, iterator_type,\n",
    "                 worker_time=30, sleep_interval=0.5):\n",
    "\n",
    "        self.stream_name = stream_name\n",
    "        self.shard_id = str(shard_id)\n",
    "        self.iterator_type = iterator_type\n",
    "        self.worker_time = worker_time\n",
    "        self.sleep_interval = sleep_interval\n",
    "\n",
    "    def process_records(self, records):\n",
    "        \"\"\"the main logic of the Consumer that needs to be implemented\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def iter_records(records):\n",
    "        for record in records:\n",
    "            part_key = record['PartitionKey']\n",
    "            data = record['Data']\n",
    "            yield part_key, data\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"poll stream for new records and pass them to process_records method\"\"\"\n",
    "        response = kinesis.get_shard_iterator(self.stream_name,\n",
    "            self.shard_id, self.iterator_type)\n",
    "\n",
    "        next_iterator = response['ShardIterator']\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        finish = start + datetime.timedelta(seconds=self.worker_time)\n",
    "\n",
    "        while finish > datetime.datetime.now():\n",
    "            try:\n",
    "                response = kinesis.get_records(next_iterator, limit=25)\n",
    "\n",
    "                records = response['Records']\n",
    "\n",
    "                if records:\n",
    "                    self.process_records(records)\n",
    "\n",
    "                next_iterator = response['NextShardIterator']\n",
    "                time.sleep(self.sleep_interval)\n",
    "            except ProvisionedThroughputExceededException as ptee:\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoConsumer(KinesisConsumer):\n",
    "    \"\"\"Consumers that echos received data to standard output\"\"\"\n",
    "    def process_records(self, records):\n",
    "        \"\"\"print the partion key and data of each incoming record\"\"\"\n",
    "        for part_key, data in self.iter_records(records):\n",
    "            print(part_key, \":\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_id = 'shardId-000000000000'\n",
    "iterator_type =  'LATEST'\n",
    "worker = EchoConsumer(stream_name, shard_id, iterator_type, worker_time=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.8.8.9 : 2021-12-12T12:22:27.082714\n",
      "8.8.8.8 : 2021-12-12T12:22:28.015056\n",
      "8.8.8.8 : 2021-12-12T12:22:30.590019\n",
      "8.8.8.9 : 2021-12-12T12:22:32.616004\n",
      "8.8.8.8 : 2021-12-12T12:22:33.126118\n"
     ]
    }
   ],
   "source": [
    "worker.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a counter class\n",
    "\n",
    "Counts the number of distinct requests from each particular IP in a specific time window, ie 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from dateutil import parser\n",
    "from operator import itemgetter\n",
    "\n",
    "class CounterConsumer(KinesisConsumer):\n",
    "    \"\"\"Consumer that counts IP occurences in 1-minute time buckets\"\"\"\n",
    "    \n",
    "    def __init__(self, stream_name, shard_id, iterator_type, worker_time):\n",
    "        self.time_buckets = defaultdict(Counter)\n",
    "        sleep_interval = 20 # seconds\n",
    "        super().__init__(stream_name, shard_id, iterator_type, worker_time, sleep_interval)\n",
    "        \n",
    "    def print_counters(self):\n",
    "        \"\"\"helper method to show counting results\"\"\"\n",
    "        \n",
    "        now = datetime.datetime.utcnow()\n",
    "        print(\"##### Last run at {}\".format(now))\n",
    "        for timestamp, ip_counts in self.time_buckets.items():\n",
    "            # sort counts with respect to the IP address\n",
    "            ip_counts = sorted(ip_counts.items(), key=itemgetter(0))\n",
    "            print(timestamp, ':', list(ip_counts))\n",
    "            \n",
    "    def process_records(self, records):\n",
    "        for ip_addr, timestamp_str in self.iter_records(records):\n",
    "            timestamp = parser.parse(timestamp_str)\n",
    "            timestamp = timestamp.replace(second=0, microsecond=0)\n",
    "            self.time_buckets[timestamp][ip_addr] += 1\n",
    "        self.print_counters()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Last run at 2021-12-12 12:23:39.984880\n",
      "2021-12-12 12:23:00 : [('8.8.8.8', 8), ('8.8.8.9', 4)]\n",
      "##### Last run at 2021-12-12 12:24:00.525199\n",
      "2021-12-12 12:23:00 : [('8.8.8.8', 16), ('8.8.8.9', 7)]\n",
      "##### Last run at 2021-12-12 12:24:21.068572\n",
      "2021-12-12 12:23:00 : [('8.8.8.8', 16), ('8.8.8.9', 7)]\n",
      "2021-12-12 12:24:00 : [('8.8.8.8', 8), ('8.8.8.9', 4)]\n",
      "##### Last run at 2021-12-12 12:24:41.622645\n",
      "2021-12-12 12:23:00 : [('8.8.8.8', 16), ('8.8.8.9', 7)]\n",
      "2021-12-12 12:24:00 : [('8.8.8.8', 16), ('8.8.8.9', 8)]\n",
      "##### Last run at 2021-12-12 12:25:02.168272\n",
      "2021-12-12 12:23:00 : [('8.8.8.8', 16), ('8.8.8.9', 7)]\n",
      "2021-12-12 12:24:00 : [('8.8.8.8', 24), ('8.8.8.9', 11)]\n"
     ]
    }
   ],
   "source": [
    "worker = CounterConsumer(stream_name, shard_id, iterator_type, worker_time=120)\n",
    "worker.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream kinesis-word-stream not found. Exiting\n",
      "stream kinesis-word-stream not found. Exiting\n"
     ]
    }
   ],
   "source": [
    "kinesis.delete_stream(stream_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
